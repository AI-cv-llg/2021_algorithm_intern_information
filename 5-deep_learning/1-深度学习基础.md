### 1，容量、欠拟合和过拟合

+  模型容量是指模型拟合各种函数的能力，决定了模型是欠拟合还是过拟合。
+  欠拟合就是指模型的训练误差过大，即偏差过大，表现为模型不够”准“，优化算法目的在于解决欠拟合问题。
+  过拟合就是指训练误差和测试误差间距过大，即方差过大，表现为模型不够”稳“，正则化目的在于解决过拟合问题。
+  机器学习模型的目的是解决欠拟合和过拟合的问题，这也是机器学习算法的两个挑战。

> 训练误差 `train error`，泛化误差 `generalization error`，也叫测试误差(`test error`)。

### 2，正则化方法

+ 正则化是指我们修改学习算法，使其降低泛化误差而非训练误差。 正则化是机器学习领域的中心问题之一，只有优化能够与其重要性相媲。
+ 正则化一个学习函数为 $f(x; θ)$ 的模型，我们可以给代价函数（损失函数）添加被称为正则化项（`regularizer`）的惩罚。
+ 正则化是一种思想（策略），给代价函数添加惩罚只是其中一种方法。另外一种最常用的正则化技术是**权重衰减**，通过加入的正则项对参数数值进行衰减，得到更小的权值。当 $\lambda$ 较大时，会使得一些权重几乎衰减到零，相当于去掉了这一项特征，类似于减少特征维度。

### 3，超参数和验证集

+ 普通参数指算法权重 $w$ 的值，是可以通过学习算法本身学习得到。**超参数的值不是通过学习算法本身学习出来的，可通过验证集人为选择合适的超参数**。
+ 将训练数据划分为两个不相交的子集，即训练集和验证集，训练集用于学习普通参数，验证集用于估计训练中或训练后的泛化误差，更新超参数（“训练超参数”）。通常，`80%` 的训练数据用于训练，`20%` 用于验证。
+ 交叉验证方法适合小规模数据集（例如几百上千张图片）训练模型的情况。

### 4，估计、偏差和方差

+ 统计领域的基本概念，例如参数估计、偏差和方差，对于正式地刻画泛化、欠拟合和过拟合都非常有帮助。**偏差和方差的关系和机器学习容量、欠拟合和过拟合的概念紧密相联**。
+ 偏差和方差度量着估计量的两个不同误差来源。偏差度量着偏离真实函数或参数的误差期望。而方差度量着数据上任意特定采样可能导致的估计期望的偏差。

### 5，随机梯度下降算法

+ 随机梯度下降算法是目前最为广泛应用的一种优化算法，形式为 $θ=θ − ϵg$，$ϵ$ 是学习率，$g$ 是梯度，$θ$ 是权重。
+ 随机梯度下降优化算法不一定能保证在合理的时间内达到一个局部最小值，但它通常能及时地找到代价函数一个很小的值，并且是有用的。
